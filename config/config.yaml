artifacts_root: artifacts
# it will create artifacts folder will store roots of every module/python/ipynb file into this folder


# create data ingestion related configuration. Which saves and provides path or URL to use it later on.
data_ingestion: # root name. Following are the subfolder.
  root_dir: artifacts/data_ingestion # root directory for downloading following URL data in source_URL below
  source_URL: https://github.com/ChaitaliKPatil/NLP_Text_Summarizer_Project/raw/master/datasets/summarizer_data.zip
  local_data_file: artifacts/data_ingestion/data.zip # above data is downloaded as data.zip
  unzip_dir: artifacts/data_ingestion # after unzipping data.zip, data will be stored in the data_ingestion directory.



data_validation:
  root_dir: artifacts/data_validation
  STATUS_FILE: artifacts/data_validation/status.txt
  ALL_REQUIRED_FILES: ["train", "test", "validation"]



data_transformation:
  root_dir: artifacts/data_transformation
  data_path: artifacts/data_ingestion/samsum_dataset
  tokenizer_name: google/pegasus-cnn_dailymail




model_trainer:
  root_dir: artifacts/model_trainer
  data_path: artifacts/data_transformation/samsum_dataset
  model_ckpt: google/pegasus-cnn_dailymail # model-checkpoint : google pegasus CNN dailymail  model.




model_evaluation:
  root_dir: artifacts/model_evaluation
  data_path: artifacts/data_transformation/samsum_dataset
  model_path: artifacts/model_trainer/pegasus-samsum-model
  tokenizer_path: artifacts/model_trainer/tokenizer
  metric_file_name: artifacts/model_evaluation/metrics.csv